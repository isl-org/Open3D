# FROM must be called before other ARGS except for ARG BASE_IMAGE
ARG BASE_IMAGE=nvidia/cuda:12.6.3-cudnn-devel-ubuntu22.04
FROM ${BASE_IMAGE}

# Customizable build arguments from cuda.yml
ARG DEVELOPER_BUILD
ARG CCACHE_TAR_NAME
ARG CMAKE_VERSION
ARG PYTHON_VERSION
ARG BUILD_TENSORFLOW_OPS
ARG BUILD_PYTORCH_OPS
ARG BUILD_PYTHON_MODULE
ARG CI

# Forward all ARG to ENV
# ci_utils.sh requires these environment variables
ENV DEVELOPER_BUILD=${DEVELOPER_BUILD}
ENV CCACHE_TAR_NAME=${CCACHE_TAR_NAME}
ENV CMAKE_VERSION=${CMAKE_VERSION}
ENV PYTHON_VERSION=${PYTHON_VERSION}
ENV BUILD_PYTORCH_OPS=${BUILD_PYTORCH_OPS}
ENV BUILD_TENSORFLOW_OPS=${BUILD_TENSORFLOW_OPS}
ENV BUILD_PYTHON_MODULE=${BUILD_PYTHON_MODULE}

# Prevent interactive inputs when installing packages
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=America/Los_Angeles
ENV SUDO=command

SHELL ["/bin/bash", "-c"]

# Dependencies: basic
RUN apt-get update && apt-get install -y \
    wget \
    ca-certificates \
    ccache \
    build-essential \
    libssl-dev \
    zlib1g-dev \
    libbz2-dev \
    libreadline-dev \
    libsqlite3-dev \
    curl \
    git \
    libncursesw5-dev \
    xz-utils \
    tk-dev \
    libxml2-dev \
    libxmlsec1-dev \
    libffi-dev \
    liblzma-dev \
 && rm -rf /var/lib/apt/lists/*

# Install NVIDIA repository keyring package
RUN wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.1-1_all.deb \
 && dpkg -i cuda-keyring_1.1-1_all.deb \
 && rm cuda-keyring_1.1-1_all.deb

# Dependencies: cmake
RUN CMAKE_VERSION_NUMBERS=$(echo "${CMAKE_VERSION}" | cut -d"-" -f2) \
 && wget -q https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION_NUMBERS}/${CMAKE_VERSION}.tar.gz \
 && tar -xf ${CMAKE_VERSION}.tar.gz \
 && cp -ar ${CMAKE_VERSION} ${HOME}
ENV PATH=${HOME}/${CMAKE_VERSION}/bin:${PATH}

# Download ccache from GCS bucket (optional)
# Example directory structure:
# CCACHE_DIR        = ~/.cache/ccache
# CCACHE_DIR_NAME   = ccache
# CCACHE_DIR_PARENT = ~/.cache
RUN ccache --version \
 && CCACHE_DIR=$(ccache -p | grep cache_dir | grep -oE "[^ ]+$") \
 && CCACHE_DIR_NAME=$(basename ${CCACHE_DIR}) \
 && CCACHE_DIR_PARENT=$(dirname ${CCACHE_DIR}) \
 && mkdir -p ${CCACHE_DIR_PARENT} \
 && cd ${CCACHE_DIR_PARENT} \
 && (wget -q https://storage.googleapis.com/open3d-ci-cache/${CCACHE_TAR_NAME}.tar.xz https://storage.googleapis.com/open3d-ci-cache/${CCACHE_TAR_NAME}.tar.gz || true) \
 && if [ -f ${CCACHE_TAR_NAME}.tar.?z ]; then tar -xf ${CCACHE_TAR_NAME}.tar.?z; fi
# We need to set ccache size explicitly with -M, otherwise the default size is
# *not* determined by ccache's default, but the downloaded ccache file's config.
RUN ccache -M 4G \
 && ccache -s

# pyenv
# The pyenv python paths are used during docker run, in this way docker run
# does not need to activate the environment again.
# The soft link from the python patch level version to the python mino version
# ensures python wheel commands (i.e. open3d) are in PATH, since we don't know
# which patch level pyenv will install (latest).
ENV PYENV_ROOT=/root/.pyenv
ENV PATH="$PYENV_ROOT/shims:$PYENV_ROOT/bin:$PYENV_ROOT/versions/$PYTHON_VERSION/bin:$PATH"
RUN curl https://pyenv.run | bash \
        && pyenv update \
        && pyenv install $PYTHON_VERSION \
        && pyenv global $PYTHON_VERSION \
        && pyenv rehash \
        && ln -s $PYENV_ROOT/versions/${PYTHON_VERSION}* $PYENV_ROOT/versions/${PYTHON_VERSION};
RUN python --version && pip --version

# Checkout Open3D-ML main branch
# TODO: We may add support for local Open3D-ML repo or pinned ML repo tag
ENV OPEN3D_ML_ROOT=/root/Open3D-ML
RUN git clone --depth 1 https://github.com/isl-org/Open3D-ML.git ${OPEN3D_ML_ROOT}

# Open3D C++ dependencies
# Done before copying the full Open3D directory for better Docker caching
COPY ./util/install_deps_ubuntu.sh /root/Open3D/util/
RUN /root/Open3D/util/install_deps_ubuntu.sh assume-yes \
 && rm -rf /var/lib/apt/lists/*

# Open3D Python dependencies
COPY ./util/ci_utils.sh /root/Open3D/util/
COPY ./python/requirements.txt /root/Open3D/python/
COPY ./python/requirements_jupyter_build.txt /root/Open3D/python/
COPY ./python/requirements_jupyter_install.txt /root/Open3D/python/
COPY ./python/requirements_build.txt /root/Open3D/python/
RUN source /root/Open3D/util/ci_utils.sh \
 && install_python_dependencies with-jupyter

# Open3D Jupyter dependencies
RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash - \
 && apt-get install -y nodejs \
 && rm -rf /var/lib/apt/lists/* \
 && node --version
RUN npm install -g yarn \
 && yarn --version

# Open3D repo
# Always keep /root/Open3D as the WORKDIR
COPY . /root/Open3D
WORKDIR /root/Open3D

# Build python wheel
# Note: BUILD_SHARED_LIBS defaults to ON, which is required for Python wheels
RUN export NPROC=$(($(nproc)+2)) \
 && source /root/Open3D/util/ci_utils.sh \
 && build_pip_package build_azure_kinect build_jupyter \
 && if [ ${CI:-}a != a ]; then rm -rf build_cpu build_cuda && if [ -d build ]; then find build -mindepth 1 -maxdepth 1 -not -name lib -exec rm -rf {} +; fi; fi
 # remove build folder (except lib) to save CI space on Github

# Compress ccache folder, move to / directory
RUN ccache -s \
 && CCACHE_DIR=$(ccache -p | grep cache_dir | grep -oE "[^ ]+$") \
 && CCACHE_DIR_NAME=$(basename ${CCACHE_DIR}) \
 && CCACHE_DIR_PARENT=$(dirname ${CCACHE_DIR}) \
 && cd ${CCACHE_DIR_PARENT} \
 && tar -caf /${CCACHE_TAR_NAME}.tar.xz ${CCACHE_DIR_NAME}

RUN echo "Docker build done."
